# Predicting brain-age from raw T1-weighted Magnetic Resonance Imaging data using 3D Convolutional Neural Networks

## url : https://arxiv.org/pdf/2103.11695.pdf

---

### Why 

Current algorithms does multiple preprocessing steps. Preprocessing steps include image registration, spatial smoothing, normalization . 
Impact of preprocessing are : 
1. Computational overhead.
2. New dataset needs to be preprocessed exactly by same applications, hampering wide spread clinical utility.

Currently, CNN is used to decrease preprocessing to only skull stripping and voxel based registration to an atlas (Bashyam et al., 2020;
Cole et al., 2017; Dinsdale et al., 2021; Hong et al., 2020).
However, registration still takes a lot of time and nonlinearly registered images can lead to artifacts.

Hong. et. al 2020 uses no preprocessing. Thus bone density and growth unrelated to actual brain aging were potential confounds.

---

### What

3D CNN based on ResNet architecture on raw, non-registered T1 weighted MRI data of N = 10.691 . 
Additionally, transfer learning on 2173 samples from 3 independent studies.

Predicts with mean average deviation 2.84 years.

Minimum preprocessing - skull stripping.

---

### Data Preparation

1. 10 fold cross validation.
2. Considered three different spatial resolutions to investigate its influence on model
performances. The highest spatial resolution considered is 134 x 168 x 134 voxels, resulting in a voxel
size of 1.36 x 1.30 x 1.36 mm, because this is found to be the average cuboid of voxels which is taken
up by the brain in the T1-weighted images in the GNC dataset. The other considered resolutions are
68 x 84 x 68 and 34 x 42 x 34 voxels, yielding a voxel size of 2.73 x 2.63 x 2.73 mm and 5.46 x 5.27 x
5.46 mm, respectively.
3. For unprocessed T1-weighted images only ran through skull stripping, cropping and resampling. For the processed data, the T1-weighted images are preprocessed with the commonly used
CAT12 toolbox.
4. The data is augmented by cropping the three-dimensional brain-scan. The size of the cropped image along each dimension
ranges from 90% to 100% of the original image and is randomly picked for each dimension individually. After cropping at a random position, 
oversampling is done via linear interpolation such that the original resolution of the skull stripped T1-scan is restored.

---

### Model architecture

1. The model which predicts brain-age from minimally preprocessed data is
a 3D convolutional neural network (CNN) with the ResNet architecture (He et al., 2016) (see Figure 1).
Two blocks, the convolutional and the residual convolutional block, are used repeatedly in this
architecture. The convolutional block starts with a convolutional layer which is followed by a rectified
linear unit (ReLU) and a 3D batch-normalization layer (Ioffe and Szegedy, 2015). The first
convolutional block in the model uses a kernel size of 7 x 7 x 7, a stride of 2 x 2 x 2, a padding of 3 x 3
x 3 and 16 output channels. All the following convolutional blocks which are part of residual
convolutional blocks take 16 respectively 32 input channels and use a kernel size of 3 x 3 x 3, a stride
of 1 x 1 x 1, a padding of 1 x 1 x 1 and 32 output channels. The first module of the residual
convolutional block is the just described convolutional block followed by a convolutional layer and a
3D batch-normalization layer.
The proposed model consists of a convolutional block followed by two residual convolutional
blocks. After the convolutional block max pooling is applied with a kernel size of 3 x 3 x 3, a stride of 2
x 2 x 2 and a padding of 1 x 1 x 1. The first residual convolutional block is followed by a convolutional layer, 
a 3D batch-normalization layer and a ReLU is applied. The second residual convolutional block is
activated by a ReLU and followed by the final module which consists of a 1D batch-normalization
layer and a dense net with a sigmoid activation function. The 3D CNN using the high resolution of 136
x 168 x 136 voxels consists of 49,820,497 parameters. The corresponding models using medium (68 x
84 x 68 voxels) and low resolution (34 x 42 x 34 voxels) consist of 6,317,905 and 1,015,633
parameters, respectively.

2. The 3D CNN is trained using the Adam W algorithm to minimize the mean squared error
(MSE) using the fastai package.

3. In addition to simply applying the pretrained model to these datasets, transfer learning is done on the
respective dataset with the same training routine which is used during the initial training with the
GNC dataset.

---

### Discussion and Future work

1. Better results than State of the art.
2. Transfer learning performs better than state of the art on new data but without transfer learning performs worse.
3. No bias with respect to gender.
4. Bias with respect to age and ethnicity. 
5. Ethnicity bias can be handled with using multiple ethnicity.







